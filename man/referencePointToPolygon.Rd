% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/referencePointToPolygon.R
\name{referencePointToPolygon}
\alias{referencePointToPolygon}
\title{Create a Rectangular Polygon Using Planar XY Coordinates}
\usage{
referencePointToPolygon(x = NULL, id = NULL, dateTime = NULL,
  point.x = NULL, point.y = NULL, StartLocation = "UL",
  UpDownRepositionLen = 1, LeftRightRepositionLen = 1,
  CenterPoint = FALSE, MidPoints = FALSE, immobThreshold = 0,
  parallel = TRUE)
}
\arguments{
\item{x}{Data frame or list of data frames containing real-time-location point data.}

\item{id}{Vector of length nrow(data.frame(x)) or singular character data, detailing the relevant colname in x, that denotes what unique ids for tracked individuals will be used. If argument == NULL, the function assumes a column with the colname "id" exists in x. Defaults to NULL.}

\item{dateTime}{Vector of length nrow(data.frame(x)) or singular character data, detailing the relevant colname in x, that denotes what dateTime information will be used. If argument == NULL, the function assumes a column with the colname "dateTime" exists in x. Defaults to NULL.}

\item{point.x}{Vector of length nrow(data.frame(x)) or singular character data, detailing the relevant colname in x, that denotes what planar-x or longitude coordinate information will be used. If argument == NULL, the function assumes a column with the colname "x" exists in x. Defaults to NULL.}

\item{point.y}{Vector of length nrow(data.frame(x)) or singular character data, detailing the relevant colname in x, that denotes what planar-y or lattitude coordinate information will be used. If argument == NULL, the function assumes a column with the colname "y" exists in x. Defaults to NULL.}

\item{StartLocation}{Character string taking the values "UL," "UR," "DL," or "DR" describing where the reference point (i.e., point corresponding to xy-coordinates in the data set) lies on the rectangle that this function will delineate. Defaults to "UL."}

\item{UpDownRepositionLen}{Numerical. Describes the height, in planar units (e.g., meters) of the output polygon. Planar units are inherent in the real-time-location input. Defaults to 1.}

\item{LeftRightRepositionLen}{Numerical. Describes the width, in planar units (e.g., meters) of the output polygon. Planar units are inherent in the real-time-location input. Defaults to 1.}

\item{CenterPoint}{Logical. If TRUE, in addition to the xy-coordinates for each polygon vertex, xy-coordinates for centroid of each polygon will be reported in the output. Defaults to FALSE.}

\item{MidPoints}{Logical. If TRUE, in addition to the xy-coordinates for each polygon vertex, xy-coordinates for mid-point of each polygon edge will be reported in the output. Defaults to FALSE.}

\item{immobThreshold}{Numerical. Describes what we call, the immobility threshold, which is a movement distance (in planar units) within which we assume individuals’ physical locations and orientations remain unchanged. This immobility threshold allows us to discount observed movements so miniscule that the majority of animals’ physical-space usage is likely unaffected (e.g., head shaking). Defaults to 0.}

\item{parallel}{Logical. If TRUE, sub-functions within the referencePointToPolygon wrapper will be parallelized. Note that this can significantly speed up processing of relatively small data sets, but may cause R to crash due to lack of available memory when attempting to process large datasets. Defaults to TRUE.}
}
\description{
This function creates a square/rectangular polygon from a single reference point by translating its location multiple times using the same method used in repositionReferencePoint. For example, even though calves in our study were only equiped with RFID tags on their left ear. With this function, we can create polygons that account for the total space used by each individual at each time step.This function is different from similar point-to-polygon functions for two reasons:
1.) It does not assume points lie within the center of the polygon. Rather, the reference point must be a corner of the polygon (Note: "UL" denotes that reference point lies on the upper-left corner of the polygon, "UR" denotes that reference point lies on the upper-right corner of the polygon,"DL" denotes that reference point lies on the down-left corner of the polygon, "DR" denotes that reference point lies on the down-left corner of the polygon). Note that if you want the reference point to be at the center of the polygon, you can first translate the reference point to a central location on tracked individuals using repositionReferencePoint.
2.) Polygon angles/directionality are based on observed movements of tracked individuals.
}
\details{
Currently, this function only supports input data with coordinates representing planar ('Euclidean') space (e.g. units of meters).

In the output, point1.x and point1.y represent the xy coordinates from the input file. Point2-n coordinates move in a clockwise direction from point1. For example: if point1 is located on the upper left ("UL") corner of the polygon, point2 would be on the upper right corner, point3 on the bottom right, and point 4 on the bottom left.

Because this function needs information (dist, dx, dy) from 2 points on an individual's path to work, at least the first point in each individual's path will be removed (the function will report NAs for adjusted locations). Also note that if the distance between an individual's first point in their path and the second one is 0, the function will also report NAs for the second point's adjusted coordinates. The first non-NA values will only be reported for the instance where dist > 0.

In the output, if input was previously processed using tempAggregate with resolutionLevel == "reduced," dt > secondAgg indicates that tracked individuals were missing in the original dataset for a period of time. In this case, the assumption that individuals are facing a given direction because they moved from the previous timepoint may not be accurate. Consider removing these rows (rows following one with dt > secondAgg; remember that dt indicates the time between recording xy coordinates in row i to row i + 1) from your dataset.
}
\examples{
#read in the calves data set
data("calves")
calves.dateTime<-datetime.append(calves, date = calves$date, time = calves$time) #create a dataframe with dateTime identifiers for location fixes.

#create our data set that shows calves average position every 10 seconds
system.time(calves.10secSmoothed <- tempAggregate(x = calves, id = calves$calftag, point.x = calves$x, point.y = calves$y, dateTime = calves$dateTime, secondAgg = 10, extrapolate.left = TRUE, resolutionLevel = "Full", extrapolate.right = FALSE, na.rm = TRUE, smooth.type = 2))

##Create 0.333 m X 0.333 m calf head polygons.
#Note that this is done using the original reference points which denote the locations of RFID tags on individuals' left ears.
system.time(calf_heads <- referencePointToPolygon(x = calves.10secSmoothed, id = calves.10secSmoothed$id, dateTime = calves.10secSmoothed$dateTime, point.x = calves.10secSmoothed$x, point.y = calves.10secSmoothed$y, StartLocation = "DL", UpDownRepositionLen = 0.333, LeftRightRepositionLen = 0.333, CenterPoint = FALSE, MidPoints = FALSE, immobThreshold = 0.1, parallel = TRUE))

#Because the head is not the same width of the body and is assumed to be centered at the front of the body, before creating body polygons, we must move reference points (on the left ear) to the left by 0.3335 m to reposition them at the upper-left corner of calves bodies. Note that we are assuming ears are parallel to shoulder-tips. 
system.time(leftShoulder.point<-repositionReferencePoint(x = calves.10secSmoothed, id = calves.10secSmoothed$id, dateTime = calves.10secSmoothed$dateTime, point.x = calves.10secSmoothed$x, point.y = calves.10secSmoothed$y, RepositionDir = "L", UpDownRepositionLen = 0, LeftRightRepositionLen = 0.3335, immobThreshold = 0, parallel = TRUE)) #Note that we do not specify a standing threshold here. Rather, we will do so when we create the polygon.

#Now we can create generate the vertices for anterior- and posterior-body polygons. Rather than running the referencePointToPolygon function twice, we instead set MidPoints = TRUE, which will effectively identify vertices for the bottom of anterior bodies/top of posterior ones. 
system.time(calf_bods <- referencePointToPolygon(x = leftShoulder.point, id = leftShoulder.point$id, dateTime = leftShoulder.point$dateTime, point.x = leftShoulder.point$x.adjusted, point.y = leftShoulder.point$y.adjusted, StartLocation = "UL", UpDownRepositionLen = 2, LeftRightRepositionLen = 1, CenterPoint = FALSE, MidPoints = TRUE, immobThreshold = 0.1, parallel = TRUE))

#Now we can take vertices from calf_heads and calf_bod, and create a vertex set {V(ij)} delineating the calves full bodies (i.e., we essentially union the calf_heads and calf_bod polygons). Note that in this calf_FullBody data frame, vertex1 is located on calves left shoulders, and vertices are ordered in a clockwise direction from that point.
calf_FullBody <- data.frame(calf_id = calf_bods$id, vertex1.x = calf_bods$cornerPoint1.x, vertex1.y = calf_bods$cornerPoint1.y, vertex2.x = calf_heads$cornerPoint4.x, vertex2.y = calf_heads$cornerPoint4.y, vertex3.x = calf_heads$cornerPoint1.x, vertex3.y = calf_heads$cornerPoint1.y, vertex4.x = calf_heads$cornerPoint2.x, vertex4.y = calf_heads$cornerPoint2.y, vertex5.x = calf_heads$cornerPoint3.x, vertex5.y = calf_heads$cornerPoint3.y, vertex6.x = calf_bods$cornerPoint2.x, vertex6.y = calf_bods$cornerPoint2.y, vertex7.x = calf_bods$cornerPoint3.x, vertex7.y = calf_bods$cornerPoint3.y, vertex8.x = calf_bods$cornerPoint4.x, vertex8.y = calf_bods$cornerPoint4.y, calf_heads[13:16], headVertices = "2,3,4,5", bodyVertices = "1,6,7,8", headArea = "0.333m X 0.333m", bodyArea = "1m X 2m")

#Additionally, we can break calf_bods into two data sets (calf_AntBod, and calf_PostBod), with identical columns to calf_heads (so the data sets can be bound together later).

calf_AntBod<-data.frame(calf_bods$id, calf_bods$cornerPoint1.x, calf_bods$cornerPoint1.y, calf_bods$cornerPoint2.x, calf_bods$cornerPoint2.y, calf_bods$midPoint2.x, calf_bods$midPoint2.y, calf_bods$midPoint4.x, calf_bods$midPoint4.y, calf_bods[,18:24])
colnames(calf_AntBod) <- colnames(calf_heads) #ensure that colnames are the same as in calf_heads

calf_PostBod<-data.frame(calf_bods$id, calf_bods$midPoint4.x, calf_bods$midPoint4.y, calf_bods$midPoint2.x, calf_bods$midPoint2.y, calf_bods$cornerPoint3.x, calf_bods$cornerPoint3.y, calf_bods$cornerPoint4.x, calf_bods$cornerPoint4.y, calf_bods[,18:24])
colnames(calf_PostBod) <- colnames(calf_heads) #ensure that colnames are the same as in calf_heads

#add a body identifier column to the data frames
calf_heads$bodyPart <-"H"
calf_AntBod$bodyPart<-"AB"
calf_PostBod$bodyPart<-"PB"

#Bind these data frames together
bindList<-list(calf_heads, calf_AntBod, calf_PostBod)
calf_polygons <- data.frame(data.table::rbindlist(bindList))

#Finally, add a unique identifier for each calf polygon, poly(i)
calf_polygons$calf_Poly.id <- paste(calf_polygons$id, calf_polygons$bodyPart, sep = "_")

#Now that we have defined the (x,y) coordinates for the vertex set V(ij), full-body, head, anterior-body, and posterior-body polygons, we can use these data sets to generate contact networks (see Supplemental Materials X).

CalfPolygonSets<-list(calf_FullBody, calf_polygons)
}
\keyword{data-processing}
\keyword{location}
\keyword{planar}
\keyword{point}
\keyword{polygon}
